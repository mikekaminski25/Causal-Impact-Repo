---
title: "Causal-Impact"
author: "Mike Kaminski"
date: "2023-03-08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Libraries
```{r message = FALSE, warning = FALSE}
library(zoo)
library(lares)
library(yfR)
library(readr)
library(tidyr)
library(dplyr)
library(CausalImpact)
library(TTR)
```

Get a list of tickers from the S&P500
```{r}
set.seed(1234)


n_tickers <- 500
df_sp500 <- yf_index_composition("SP500")
rnd_tickers <- base::sample(df_sp500$ticker, n_tickers)

# cat(paste0("The selected tickers are: ",
#             paste0(rnd_tickers, collapse = ", ")))
```

Extract prices from yahoo finance
```{r message = FALSE, warning = FALSE}
df_yf <- yf_get(tickers = rnd_tickers,
                first_date = '2020-01-02',
                last_date = Sys.Date())
head(df_yf)
```

Remove unnecessary columns and add a 5, 10, and 20 day moving average.  These will come into play later in the code
```{r}
df_stocks <- df_yf %>%
  select(ticker, ref_date, price_close) %>%
  group_by(ticker) %>%
  mutate(mov_avg5 = SMA(price_close, n =5)) %>%
  mutate(mov_avg10 = SMA(price_close, n =10)) %>%
  mutate(mov_avg20 = SMA(price_close, n =20))%>%
  mutate(ref_date = as.Date(ref_date)) %>%
  mutate(price_close = as.numeric(price_close)) %>%
  ungroup()

```

Stocks are only priced on days the markets are open, so a sequence of dates has been created to account for the days when there wasn't a closing price.  Dates are right joined by the sequence of dates by ticker. Any day the market is closed means that the price_close value is zero
```{r}
df_date <- df_stocks %>%
  group_by(ticker) %>%
  complete(ref_date = seq.Date(as.Date('2019-12-29'), Sys.Date(), by="day"))
```

This block of code inserts the 10-day moving average when a value is blank.  5 or 20-day moving average can be used as well. January 15th 2020 is the first day that a 10-day moving average is available, so the date is filtered on that value  
```{r}
df_stocks1 <- df_date %>%
  group_by(ticker) %>%
  fill(mov_avg10, .direction = "downup")  %>%
  mutate(price_close = ifelse(is.na(price_close), mov_avg10, price_close))  %>%
  select(c(ticker,ref_date,price_close)) %>%
  filter(ref_date >= '2020-01-15') %>%
  mutate(price_close = round(price_close,2))
```

This line of code imports the sales data.
```{r}
df_sales <- read.csv(file.choose())
```

Converts sales_df date to appropriate date format.
This also creates a 7days moving average for sales since the data has some daily seasonality
```{r}
df_sales$Date <- as.Date(df_sales$Date, format = "%m/%d/%Y")
df_sales_7dma <- df_sales %>%
  mutate(mov_avg7 = round(SMA(Sales, n =7),2))
```

This merges the sales and stocks data
```{r}
df_final <- merge(df_stocks1, df_sales, by.x='ref_date',by.y='Date', all.x=TRUE) %>% 
  pivot_wider(names_from = ticker, values_from = price_close) %>%
  filter(Sales >=0) %>%
  as.data.frame()

```

This merges the sales 7dma and the stocks data
```{r}
df_final_7dma <- merge(df_stocks1, df_sales_7dma, by.x='ref_date',by.y='Date', all.x=TRUE) %>% 
  select(-c(Sales)) %>%
  pivot_wider(names_from = ticker, values_from = price_close) %>%
  filter(mov_avg7 >=0) %>%
  as.data.frame()
```

In order to create a synthetic control group aka a baseline, we want to see which securities are most related to the number of sales.  Initially I'll use raw values, but log values and 7dma values might be interesting to look at as well.

```{r}
m <- df_final[,-1]
a <- corr_var(m,
              Sales,
              top = 25,
              #max_pvalue = 0.05
              )
plot(a, cex = .5,cex.axis=.5)
```
Correlations don't look too useful, the most correlated is MOH with a corr of -0.54.  We'll try with log values of sales

```{r}
m_log <- log(df_final[,-1])
a_log <- corr_var(m_log,
              Sales,
              top = 25,
              #max_pvalue = 0.05
              )
plot(a_log, cex = .5,cex.axis=.5)
```

These results are actually worse than before.  There might be too much variablity in the daily sales data, so we'll check against the 7dma

```{r}
m_7dma <- df_final_7dma[,-1]
a_7dma <- corr_var(m_7dma,
              mov_avg7,
              top = 100,
              #max_pvalue = 0.05
              )
plot(a_7dma, cex = .5,cex.axis=.5)
```

These results look a lot better.  The top 25 range from -.783 to -.727.  Lets look at the top 100

```{r}
m_7dma <- df_final_7dma[,-1]
a_7dma <- corr_var(m_7dma,
              mov_avg7,
              top = 100,
              #max_pvalue = 0.05
              )
# plot(a_7dma, cex = .5,cex.axis=.5) #the plot looks messy, but the values are included below
a_7dma$data$corr
a_7dma$data$variables
```
57 of the top 100 stocks are above +/- 0.695, so we can take those and use as our baseline.

We can try using the log of the 7dma as well
```{r}
m_7dma_log <- log(df_final_7dma[,-1])
a_7dma_log <- corr_var(m_7dma_log,
              mov_avg7,
              top = 100,
              #max_pvalue = 0.05
              )
plot(a_7dma_log, cex = .5,cex.axis=.5) #the plot looks messy, but the values are included below
cor_log_7 <- a_7dma_log$data$corr
stock_log_7 <-a_7dma_log$data$variables
log_7 <- data.frame(col1 = stock_log_7,col2 =cor_log_7) #creates a dataframe to review
head(log_7)
which(abs(a_7dma_log$data$corr) >= (0.68))

```
When we take the log of sales, we actually get higher correlations, which will act better for our baseline.  Just need to remember to take reverse log out of the final values

Modeling

Need to establish the pre and post periods.  These periods can be shortened as we tune the model if needed. Start date will be 03-01-2020 since that's the first full month of data.  The intervention (price increase) occurred on the first of the year in 2023. A variable called time points is created for the Causal Impact model
```{r}
pre.start <- "2020-03-01" #start of pre period
pre.end <- "2022-12-31" #end of pre period
post.start <- "2023-01-01" #intervention start
post.end <- "2023-02-28" #end of data/intervention end

pre.period <- as.Date(c(pre.start, pre.end))
post.period <- as.Date(c(post.start,post.end))

time.points <- df_final_7dma[,1]
```


Other variables are created for the model as well.  The first 50 most correlated stocks will be used initially.  The top 100 were all above +/- 0.678474, so it might be worth exploring all 100 or even more - anything above +/- 0.65 maybe
```{r}
corr_stonks <- a_7dma_log$data$variables[1:50] #names of stocks from log of 7dma

df_final_7dma$mov_avg7_log <- log(df_final_7dma$mov_avg7) #creates log values based on 7dma

stonks <- as_tibble(df_final_7dma[,c('mov_avg7_log',corr_stonks)]) #creates a tibble for the model

baseline <- zoo(stonks, order.by = time.points) #creates a time series for stocks and time.points
baseline_log <- zoo(stonks, order.by = time.points) #creates a time series for stocks and time.points
```

Seasonality Tests

First attempt with default values for the arguments - no seasonality
```{r}
impact_none <- CausalImpact(baseline, 
                            pre.period, 
                            post.period,
                            alpha = 0.05,
                            model.args = list(
                            niter = 10000
                            # prior.level.sd = 0.01, #default is 0.01
                            # nseasons = 12, #default is 1
                            # season.duration = 30, #default is 1
                            # dynamic.regression = FALSE, #default is FALSE
                            # max.flips = 10000 #default is -1
                           )
                        )

summary(impact_none)
# impact_none$model$model.args

```

Adding in Daily Seasonality
```{r}
ptm <- proc.time() #starts the clock

impact_daily <- CausalImpact(baseline, 
                            pre.period, 
                            post.period,
                            alpha = 0.05,
                            model.args = list(
                            niter = 10000,
                            # prior.level.sd = 0.01, #default is 0.01
                            nseasons = 7, #default is 1
                            season.duration = 1 #default is 1
                            # dynamic.regression = FALSE, #default is FALSE
                            # max.flips = 10000 #default is -1
                           )
                        )

summary(impact_daily)
# impact_none$model$model.args

proc.time() - ptm #stops the clock
```

Weekly seasonality
```{r}
ptm <- proc.time() #starts the clock

impact_weekly <- CausalImpact(baseline, 
                            pre.period, 
                            post.period,
                            alpha = 0.05,
                            model.args = list(
                            niter = 10000,
                            # prior.level.sd = 0.01, #default is 0.01
                            nseasons = 52, #default is 1
                            season.duration = 7 #default is 1
                            # dynamic.regression = FALSE, #default is FALSE
                            # max.flips = 10000 #default is -1
                           )
                        )

summary(impact_weekly)
# impact_none$model$model.args

proc.time() - ptm #stops the clock

```


Monthly
```{r}
ptm <- proc.time() #starts the clock

impact_monthly <- CausalImpact(baseline, 
                            pre.period, 
                            post.period,
                            alpha = 0.05,
                            model.args = list(
                            niter = 10000,
                            # prior.level.sd = 0.01, #default is 0.01
                            nseasons = 12, #default is 1
                            season.duration = 30 #default is 1
                            # dynamic.regression = FALSE, #default is FALSE
                            # max.flips = 10000 #default is -1
                           )
                        )

summary(impact_monthly)
# impact_none$model$model.args

proc.time() - ptm #stops the clock
```

daily has the lowest, but no seasonality and monthly are pretty close.  hyperparatmer tuning will be done for daily seasonality.
```{r}
init_results <- data.frame(none = impact_none$summary$p[1],
                           daily = impact_daily$summary$p[1],
                           weekly = impact_weekly$summary$p[1],
                           monthly = impact_monthly$summary$p[1])
init_results

```

